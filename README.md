# ğŸ•¹ï¸ Chatbot RAG v1.0 - Terminal Retro Edition# ğŸ•¹ï¸ Chatbot RAG v1.0 - Terminal Retro Edition



Sistema de chatbot inteligente com **visual retro anos 90** que responde perguntas baseadas em documentos PDF usando **RAG (Retrieval-Augmented Generation)** avanÃ§ado com **re-ranking** e **streaming de respostas**.Sistema de chatbot inteligente com **visual retro anos 90** que responde perguntas baseadas em documentos PDF usando **RAG (Retrieval-Augmented Generation)** avanÃ§ado com **re-ranking** e **streaming de respostas**.



```

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

â•‘  CHATBOT RAG v1.0 - TERMINAL RETRO EDITION    â•‘

â•‘  (C) 2025 - RAG TERMINAL SYSTEMS               â•‘## ğŸ¯ CaracterÃ­sticas Principais

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

```### ğŸš€ **RAG AvanÃ§ado com Re-Ranking**

- **Cross-Encoder Re-Ranking**: Usa modelo `ms-marco-MiniLM-L-6-v2` para reordenar resultados

---- **Busca em 2 Etapas**: Fetch 10 documentos â†’ Score com cross-encoder â†’ Seleciona top 4

- **PrecisÃ£o Aumentada**: 30-40% melhor relevÃ¢ncia vs busca por embeddings pura

## ğŸ¯ CaracterÃ­sticas Principais

### âš¡ **Streaming de Respostas em Tempo Real**

### ğŸš€ **RAG AvanÃ§ado com Re-Ranking**- **Output Palavra-por-Palavra**: Respostas aparecem enquanto sÃ£o geradas

- **Cross-Encoder Re-Ranking**: Usa modelo `ms-marco-MiniLM-L-6-v2` para reordenar resultados- **Feedback InstantÃ¢neo**: Veja o bot "pensando" em tempo real

- **Busca em 2 Etapas**: Fetch 10 documentos â†’ Score com cross-encoder â†’ Seleciona top 4- **Performance Percebida**: Interface mais responsiva e dinÃ¢mica

- **PrecisÃ£o Aumentada**: 30-40% melhor relevÃ¢ncia vs busca por embeddings pura

### ğŸ“š **CitaÃ§Ãµes de Fontes Inteligentes**

### âš¡ **Streaming de Respostas em Tempo Real**- **Snippets Contextuais**: 200 caracteres de contexto por fonte

- **Output Palavra-por-Palavra**: Respostas aparecem enquanto sÃ£o geradas- **Truncamento Inteligente**: Quebra em limites de palavras, nÃ£o no meio

- **Feedback InstantÃ¢neo**: Veja o bot "pensando" em tempo real- **Rastreabilidade**: Nome do arquivo, pÃ¡gina e trecho exato citado

- **Performance Percebida**: Interface mais responsiva e dinÃ¢mica

### ğŸ¨ **Visual Retro Terminal Anos 90**

### ğŸ“š **CitaÃ§Ãµes de Fontes Inteligentes**- **EstÃ©tica CRT**: Monitor fosforescente verde sobre fundo preto

- **Snippets Contextuais**: 200 caracteres de contexto por fonte- **ASCII Art**: Bordas e tÃ­tulos estilo DOS/Unix

- **Truncamento Inteligente**: Quebra em limites de palavras, nÃ£o no meio- **Cores Neon**: Verde (#00ff00), Ciano (#00ffff), Amarelo (#ffff00)

- **Rastreabilidade**: Nome do arquivo, pÃ¡gina e trecho exato citado- **Mensagens Terminal**: Sistema com prefixos `>>>` estilo command-line

- **BotÃµes Retro**: Estilo DOS com prefixos `[SÃMBOLO]`

### ğŸ¨ **Visual Retro Terminal Anos 90**- **Cursor Largo**: 8px tipo DOS piscante

- **EstÃ©tica CRT**: Monitor fosforescente verde sobre fundo preto

- **ASCII Art**: Bordas e tÃ­tulos estilo DOS/Unix### ğŸ’» **Interface GrÃ¡fica Completa**

- **Cores Neon**: Verde (#00ff00), Ciano (#00ffff), Amarelo (#ffff00)- **Tkinter Modern**: GUI com tema retro escuro

- **Mensagens Terminal**: Sistema com prefixos `>>>` estilo command-line- **Terminal Integrado**: Output estilo console com cores diferenciadas

- **BotÃµes Retro**: Estilo DOS com prefixos `[SÃMBOLO]`- **OperaÃ§Ãµes AssÃ­ncronas**: Threading para nÃ£o travar a interface

- **Cursor Largo**: 8px tipo DOS piscante- **Feedback Visual**: Status de carregamento e processamento



### ğŸ’» **Interface GrÃ¡fica Completa**### ğŸ”’ **100% Local e Privado**

- **Tkinter Modern**: GUI com tema retro escuro- **Sem Internet**: Tudo roda localmente apÃ³s setup inicial

- **Terminal Integrado**: Output estilo console com cores diferenciadas- **Privacidade Total**: Seus documentos nunca saem do seu computador

- **OperaÃ§Ãµes AssÃ­ncronas**: Threading para nÃ£o travar a interface- **Ollama Local**: LLM e embeddings rodando na sua mÃ¡quina

- **Feedback Visual**: Status de carregamento e processamento



### ğŸ”’ **100% Local e Privado**

- **Sem Internet**: Tudo roda localmente apÃ³s setup inicialO Ollama Ã© necessÃ¡rio para executar os modelos de IA localmente.

- **Privacidade Total**: Seus documentos nunca saem do seu computador

- **Ollama Local**: LLM e embeddings rodando na sua mÃ¡quina## ğŸš€ Como Usar



---#### InstalaÃ§Ã£o do Ollama:



## ğŸ“‹ PrÃ©-requisitos1. Acesse: https://ollama.ai/download### 1. Executar a AplicaÃ§Ã£o



### 1. **Python 3.8+**2. Baixe e instale o Ollama para Windows```bash

Verifique sua versÃ£o:

```bash3. Verifique a instalaÃ§Ã£o: `ollama --version`python main.py

python --version

``````



### 2. **Ollama** (Servidor LLM Local)#### Baixar os Modelos NecessÃ¡rios:



#### InstalaÃ§Ã£o:ApÃ³s instalar o Ollama, execute os seguintes comandos:### 2. Interface Principal

1. Acesse: https://ollama.ai/download

2. Baixe e instale para Windows

3. Verifique: `ollama --version`

```bashA aplicaÃ§Ã£o abrirÃ¡ uma janela com:

#### Modelos NecessÃ¡rios:

```bash# Modelo de embeddings (para vetorizaÃ§Ã£o de documentos)

# Embeddings (vetorizaÃ§Ã£o de documentos)

ollama pull nomic-embed-textollama pull nomic-embed-text#### ğŸ“Š BotÃµes Principais:



# LLM (geraÃ§Ã£o de respostas)- **ğŸ“„ Adicionar PDF**: Abre um diÃ¡logo para selecionar arquivos PDF

ollama pull deepseek-r1:8b

```# Modelo de linguagem (para geraÃ§Ã£o de respostas)- **ğŸ“ Listar Arquivos**: Mostra todos os PDFs adicionados ao armazÃ©m



**Nota**: Download dos modelos ~5GB, pode demorar alguns minutos.ollama pull deepseek-r1:8b- **ğŸ—‘ï¸ Limpar Terminal**: Limpa o terminal integrado



#### Verificar InstalaÃ§Ã£o:```

```bash

ollama list#### ğŸ’» Terminal Integrado:

```

VocÃª deve ver `nomic-embed-text` e `deepseek-r1:8b` listados.**Nota**: O download dos modelos pode levar alguns minutos dependendo da sua conexÃ£o.- Mostra todas as operaÃ§Ãµes e respostas do sistema



---- Interface de console em modo escuro



## ğŸš€ InstalaÃ§Ã£o RÃ¡pida#### Verificar se o Ollama estÃ¡ rodando:- Scroll automÃ¡tico para acompanhar as mensagens



### 1. Clone o RepositÃ³rio```bash

```bash

git clone https://github.com/victormedrado99/local_chatbot_RAG.gitollama list#### ğŸ’¬ Campo de Chat:

cd local_chatbot_RAG

``````- Digite suas perguntas no campo inferior



### 2. Crie Ambiente Virtual (Recomendado)VocÃª deve ver os modelos `nomic-embed-text` e `deepseek-r1:8b` listados.- Pressione **Enter** ou clique em **ğŸ“¤ Enviar**

```bash

python -m venv .venv- O chatbot responderÃ¡ baseado nos documentos adicionados

```

## ğŸš€ InstalaÃ§Ã£o do Projeto

### 3. Ative o Ambiente Virtual

## ğŸ”§ Funcionalidades

**Windows (PowerShell):**

```powershell### 1. Clone ou baixe o repositÃ³rio

.venv\Scripts\activate

``````bash### Adicionar Documentos PDF



**Windows (CMD):**git clone https://github.com/victormedrado99/local_chatbot_RAG.git1. Clique em **ğŸ“„ Adicionar PDF**

```cmd

.venv\Scripts\activate.batcd local_chatbot_RAG2. Selecione um ou mais arquivos PDF

```

```3. O sistema processarÃ¡ e adicionarÃ¡ ao armazÃ©m automaticamente

**Linux/Mac:**

```bash4. Uma mensagem de confirmaÃ§Ã£o aparecerÃ¡ no terminal

source .venv/bin/activate

```### 2. Crie um ambiente virtual (recomendado)



### 4. Instale DependÃªncias```bash### Fazer Perguntas

```bash

pip install langchain langchain-community langchain-core langchain-chroma langchain-ollama chromadb pymupdf sentence-transformerspython -m venv .venv1. Digite sua pergunta no campo inferior

```

```2. Pressione Enter ou clique em **ğŸ“¤ Enviar**

### 5. Execute o Chatbot

```bash3. O sistema buscarÃ¡ informaÃ§Ãµes relevantes nos documentos

python main.py

```### 3. Ative o ambiente virtual4. A resposta aparecerÃ¡ no terminal



---



## ğŸ’» Como Usar**Windows (PowerShell):**### Listar Documentos



### Interface Retro Terminal```powershell1. Clique em **ğŸ“ Listar Arquivos**



Ao executar `python main.py`, vocÃª verÃ¡:.venv\Scripts\activate2. O terminal mostrarÃ¡ todos os PDFs no armazÃ©m



``````

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

â•‘  CHATBOT RAG v1.0 - SISTEMA INICIALIZADO      â•‘## âš™ï¸ ConfiguraÃ§Ãµes

â•‘  (C) 2025 - RAG TERMINAL SYSTEMS               â•‘

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•**Windows (CMD):**



Digite sua pergunta no prompt e pressione ENTER.```cmd### Modelos Configurados:

Digite [?] HELP para ver comandos disponÃ­veis.

.venv\Scripts\activate.bat- **LLM**: `deepseek-r1:8b` (via Ollama)

>>> CARREGANDO MODELOS DE IA...

>>> LOADING: Cross-Encoder Re-Ranking Module...```- **Embeddings**: `nomic-embed-text`

>>> STATUS: Re-ranking [ENABLED]

- **Banco Vetorial**: ChromaDB (persistente)

>>> SYSTEM READY - All models loaded successfully!

>>> Type your query below:**Linux/Mac:**



> _```bash### DiretÃ³rio de Dados:

```

source .venv/bin/activate- **ArmazÃ©m**: `./meu_armazem_chroma`

### BotÃµes DisponÃ­veis

```

```

[+] ADD DOC    - Adicionar documentos PDF## ğŸ¨ Interface

[â‰¡] LIST       - Listar todos os PDFs no armazÃ©m

[-] REMOVE     - Remover documentos do banco### 4. Instale as dependÃªncias

[?] HELP       - Exibir ajuda e comandos

[X] CLEAR      - Limpar terminal```bash### Design:

```

pip install langchain langchain-community langchain-core langchain-chroma langchain-ollama chromadb pymupdf- **Tema**: Modo escuro moderno

### Workflow de Uso

```- **Cores**: Cinza escuro com texto branco

1. **Adicione Documentos PDF**:

   - Clique em `[+] ADD DOC`- **Fonte**: Consolas para terminal, Arial para interface

   - Selecione um ou mais arquivos PDF

   - Aguarde processamento: `>>> LOADING: Processing PDF...`## ğŸ¯ Como Usar- **Emojis**: Interface amigÃ¡vel com Ã­cones visuais

   - ConfirmaÃ§Ã£o: `>>> STATUS: Document added successfully!`



2. **FaÃ§a Perguntas**:

   - Digite no prompt: `> sua pergunta aqui`### 1. Certifique-se que o Ollama estÃ¡ rodando### Layout:

   - Pressione **Enter**

   - Veja processamento: `>>> PROCESSING QUERY...`O Ollama deve estar em execuÃ§Ã£o em segundo plano. Normalmente ele inicia automaticamente apÃ³s a instalaÃ§Ã£o.```



3. **Receba Resposta com Streaming**:â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

   ```

   >>> OUTPUT:Para iniciar manualmente (se necessÃ¡rio):â”‚          ğŸ¤– Chatbot RAG - IA com Documentos     â”‚

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

   Sua resposta aparece palavra por palavra em```bashâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

   tempo real, simulando um terminal processando...

   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ollama serveâ”‚ [ğŸ“„ Adicionar PDF] [ğŸ“ Listar] [ğŸ—‘ï¸ Limpar]    â”‚

   ```

```â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

4. **Veja Fontes com Contexto**:

   ```â”‚                                                 â”‚

   >>> SOURCES REFERENCED:

   ### 2. Execute o programaâ”‚               ğŸ’» Terminal                       â”‚

     [1] Documento.pdf (pÃ¡g. 5)

         "...trecho de 200 caracteres do documento```bashâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚

         mostrando o contexto exato da citaÃ§Ã£o..."

   python main.pyâ”‚  â”‚ SaÃ­da do sistema aqui...                â”‚    â”‚

     [2] Outro_Doc.pdf (pÃ¡g. 12)

         "...mais contexto relevante da fonte..."```â”‚  â”‚                                         â”‚    â”‚

   ```

â”‚  â”‚                                         â”‚    â”‚

---

Ou, se estiver usando ambiente virtual:â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚

## ğŸ¨ Visual Retro Anos 90

```bashâ”‚                                                 â”‚

### Paleta de Cores

.venv\Scripts\python.exe main.pyâ”‚ ğŸ’¬ Pergunta: [_______________] [ğŸ“¤ Enviar]     â”‚

| Elemento | Cor | Hex | InspiraÃ§Ã£o |

|----------|-----|-----|------------|```â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

| **Bot** | Verde Neon | `#00ff00` | Terminais Unix/DOS |

| **UsuÃ¡rio** | Ciano | `#00ffff` | IBM PC, MS-DOS |```

| **Fontes** | Amarelo | `#ffff00` | Avisos DOS/BIOS |

| **Prompt** | Branco | `#ffffff` | Cursor padrÃ£o |### 3. Interface do Chatbot

| **Fundo** | Preto Total | `#000000` | Monitor CRT |

## ğŸ› ï¸ Tecnologias Utilizadas

### Elementos Visuais

A janela do chatbot abrirÃ¡ com os seguintes botÃµes:

- **ASCII Art Borders**: `â•”â•â•â•â•—` `â•‘   â•‘` `â•šâ•â•â•â•`

- **Separadores**: `â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`- **Python 3.8+**

- **Prefixos Terminal**: `>>>` `> `

- **BotÃµes DOS**: `[SÃMBOLO]` estilo- **ğŸ“„ Adicionar PDF**: Clique para selecionar e adicionar documentos PDF ao armazÃ©m- **Tkinter**: Interface grÃ¡fica

- **Fonte**: Courier New Bold (monoespaÃ§ada)

- **Cursor**: 8px largo tipo DOS- **ğŸ“ Listar Arquivos**: Mostra todos os PDFs que foram adicionados- **LangChain**: Framework para IA e RAG



### InspiraÃ§Ã£o- **â“ Ajuda**: Exibe instruÃ§Ãµes de uso no terminal- **ChromaDB**: Banco de dados vetorial



âœ¨ **DOS/Unix Terminals** (1980-1995)  - **ğŸ—‘ï¸ Limpar**: Limpa o terminal de chat- **Ollama**: Servidor de LLM local

âœ¨ **BBS Systems** com ASCII art  

âœ¨ **Monitores CRT** fosforescentes  - **PyMuPDF**: Processamento de PDFs

âœ¨ **Cyberpunk Retro** aesthetic

### 4. Workflow de Uso

ğŸ“„ **DocumentaÃ§Ã£o Completa**: Ver `VISUAL_RETRO_90s.md`

## ğŸ“ DependÃªncias

---

1. **Adicione documentos PDF**:

## âš™ï¸ Tecnologias e ConfiguraÃ§Ã£o

   - Clique em "Adicionar PDF"Instale as dependÃªncias necessÃ¡rias:

### Stack TecnolÃ³gico

   - Selecione um arquivo PDF do seu computador

| Componente | Tecnologia | VersÃ£o/Modelo |

|------------|------------|---------------|   - Aguarde a confirmaÃ§Ã£o: "Arquivo adicionado com sucesso!"```bash

| **LLM** | Ollama | deepseek-r1:8b |

| **Embeddings** | Ollama | nomic-embed-text |pip install langchain langchain-community langchain-core langchain-chroma chromadb pymupdf

| **Re-Ranking** | Sentence-Transformers | ms-marco-MiniLM-L-6-v2 |

| **Vector DB** | ChromaDB | 1.3.4 |2. **FaÃ§a perguntas**:```

| **Framework** | LangChain | Community + Core |

| **GUI** | Tkinter | Python Standard Lib |   - Digite sua pergunta no campo de entrada na parte inferior

| **PDF Parser** | PyMuPDF | Latest |

   - Pressione Enter ou clique em "Enviar"## ğŸš€ InicializaÃ§Ã£o RÃ¡pida

### Arquitetura RAG com Re-Ranking

   - O bot processarÃ¡ e responderÃ¡ baseado nos documentos

```

[Pergunta do UsuÃ¡rio]1. **Clone ou baixe o projeto**

        â†“

[Embedding com nomic-embed-text]3. **Liste os arquivos** (opcional):2. **Instale as dependÃªncias**

        â†“

[Busca Vetorial no ChromaDB] â†’ Retorna 10 documentos   - Clique em "Listar Arquivos" para ver todos os PDFs adicionados3. **Certifique-se que o Ollama estÃ¡ rodando com o modelo deepseek-r1:8b**

        â†“

[Cross-Encoder Re-Ranking] â†’ Score cada doc com ms-marco4. **Execute**: `python main.py`

        â†“

[Top 4 Documentos Selecionados]## âš™ï¸ ConfiguraÃ§Ã£o5. **Adicione seus PDFs e comece a conversar!**

        â†“

[Contexto + Pergunta â†’ deepseek-r1:8b]

        â†“

[Streaming de Resposta] â†’ Output palavra-por-palavra### Modelos Configurados---

        â†“

[CitaÃ§Ã£o de Fontes com Snippets]Os modelos podem ser alterados no arquivo `main.py`:

```

> **Nota**: Este sistema requer que o Ollama esteja rodando localmente com os modelos `deepseek-r1:8b` e `nomic-embed-text` instalados.

### ConfiguraÃ§Ãµes PadrÃ£o```python

DB_PATH = './meu_armazem_chroma'  # DiretÃ³rio do banco vetorial

```pythonEMBED_MODEL = 'nomic-embed-text'   # Modelo de embeddings

# main.pyLLM_MODEL = 'deepseek-r1:8b'       # Modelo de linguagem

DB_PATH = './meu_armazem_chroma'           # Banco vetorial local```

EMBED_MODEL = 'nomic-embed-text'            # Modelo embeddings

LLM_MODEL = 'deepseek-r1:8b'                # Modelo linguagem### Modelos Alternativos no Ollama

RERANKER_MODEL = 'ms-marco-MiniLM-L-6-v2'  # Cross-encoderVocÃª pode usar outros modelos disponÃ­veis no Ollama:

INITIAL_K = 10                              # Docs iniciais

FINAL_K = 4                                 # Docs apÃ³s re-rank**Para o LLM (geraÃ§Ã£o de respostas):**

SNIPPET_LENGTH = 200                        # Chars por fonte- `llama3`

```- `mistral`

- `gemma`

### Modelos Alternativos- `phi3`



VocÃª pode usar outros modelos do Ollama:Para trocar, baixe o modelo e altere `LLM_MODEL` no cÃ³digo:

```bash

**LLMs CompatÃ­veis:**ollama pull llama3

- `llama3` - Meta's Llama 3```

- `mistral` - Mistral AI

- `gemma` - Google Gemma## ğŸ—‚ï¸ Estrutura do Projeto

- `phi3` - Microsoft Phi-3

```

**Para trocar:**local_chatbot_RAG/

```bashâ”œâ”€â”€ main.py                    # CÃ³digo principal da aplicaÃ§Ã£o

ollama pull llama3â”œâ”€â”€ README.md                  # Este arquivo

# Altere LLM_MODEL no main.pyâ”œâ”€â”€ .gitignore                 # Arquivos ignorados pelo Git

```â”œâ”€â”€ .venv/                     # Ambiente virtual (apÃ³s criaÃ§Ã£o)

â””â”€â”€ meu_armazem_chroma/        # Banco de dados vetorial (criado automaticamente)

---```



## ğŸ—‚ï¸ Estrutura do Projeto## ğŸ”§ Troubleshooting



```### Erro: "No module named 'langchain_ollama'"

local_chatbot_RAG/**SoluÃ§Ã£o**: Instale o pacote:

â”œâ”€â”€ main.py                       # AplicaÃ§Ã£o principal (690+ linhas)```bash

â”œâ”€â”€ README.md                     # Este arquivopip install langchain-ollama

â”œâ”€â”€ VISUAL_RETRO_90s.md          # Doc visual retro completo```

â”œâ”€â”€ RERANKING.md                 # Doc tÃ©cnico re-ranking

â”œâ”€â”€ STREAMING.md                 # Doc implementaÃ§Ã£o streaming### Erro: "model 'nomic-embed-text' not found"

â”œâ”€â”€ FONTES_MELHORADAS.md         # Doc sistema citaÃ§Ãµes**SoluÃ§Ã£o**: Baixe o modelo de embeddings:

â”œâ”€â”€ .gitignore                   # Git ignore patterns```bash

â”œâ”€â”€ .venv/                       # Ambiente virtual Pythonollama pull nomic-embed-text

â””â”€â”€ meu_armazem_chroma/          # ChromaDB (criado auto)```

    â”œâ”€â”€ chroma.sqlite3

    â””â”€â”€ [embeddings vectors]### Erro: "model 'deepseek-r1:8b' not found"

```**SoluÃ§Ã£o**: Baixe o modelo de linguagem:

```bash

---ollama pull deepseek-r1:8b

```

## ğŸ”§ Troubleshooting

### Erro: "Connection refused" ao adicionar PDF

### âŒ Erro: "No module named 'sentence_transformers'"**SoluÃ§Ã£o**: Certifique-se que o Ollama estÃ¡ rodando:

```bash```bash

pip install sentence-transformersollama serve

``````



### âŒ Erro: "model 'nomic-embed-text' not found"### Programa nÃ£o abre a janela

```bash**SoluÃ§Ã£o**: Verifique se o tkinter estÃ¡ instalado:

ollama pull nomic-embed-text```bash

```python -m tkinter

```

### âŒ Erro: "model 'deepseek-r1:8b' not found"Se nÃ£o funcionar, reinstale o Python com suporte a tkinter.

```bash

ollama pull deepseek-r1:8b## ğŸ“Š Requisitos de Sistema

```

- **RAM**: MÃ­nimo 8GB (recomendado 16GB para modelos maiores)

### âŒ Erro: "Connection refused" ao adicionar PDF- **Armazenamento**: ~5GB para os modelos

**Causa**: Ollama nÃ£o estÃ¡ rodando- **Sistema Operacional**: Windows 10/11, Linux, macOS

- **ConexÃ£o**: NecessÃ¡ria apenas para download inicial dos modelos

**SoluÃ§Ã£o**:

```bash## ğŸ›¡ï¸ Privacidade

ollama serve

```- âœ… Todos os dados sÃ£o processados **localmente**

- âœ… Nenhuma informaÃ§Ã£o Ã© enviada para servidores externos

### âŒ Programa nÃ£o abre a janela- âœ… Seus documentos ficam apenas no seu computador

**Causa**: Tkinter nÃ£o instalado

## ğŸ¨ Interface

**SoluÃ§Ã£o**:

```bash### Design:

# Teste tkinter- **Tema**: Modo escuro moderno

python -m tkinter- **Terminal integrado**: Para interaÃ§Ã£o e visualizaÃ§Ã£o de respostas

- **BotÃµes intuitivos**: FÃ¡cil navegaÃ§Ã£o

# Se falhar, reinstale Python com suporte GUI

```### Layout:

```

### âŒ Re-ranking lento na primeira vezâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

**Causa**: Download do modelo ms-marco (~90MB)â”‚          ğŸ¤– Chatbot RAG                         â”‚

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

**SoluÃ§Ã£o**: Aguarde o download automÃ¡tico na primeira execuÃ§Ã£o.â”‚ [ğŸ“„ PDF] [ğŸ“ Listar] [â“ Ajuda] [ğŸ—‘ï¸ Limpar]    â”‚

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

### âŒ Cores nÃ£o aparecem corretamenteâ”‚                                                 â”‚

**Causa**: Tags de cor aplicadas incorretamenteâ”‚               ğŸ’» Terminal Chat                  â”‚

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚

**SoluÃ§Ã£o**: As cores foram corrigidas! Se persistir, reinicie o programa.â”‚  â”‚ Bot: Bem-vindo ao Chatbot RAG!          â”‚    â”‚

â”‚  â”‚                                         â”‚    â”‚

---â”‚  â”‚                                         â”‚    â”‚

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚

## ğŸ“Š Requisitos de Sistemaâ”‚                                                 â”‚

â”‚ [_______________entrada_______________] [Enviar]â”‚

| Requisito | MÃ­nimo | Recomendado |â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

|-----------|--------|-------------|```

| **RAM** | 8GB | 16GB |

| **Armazenamento** | 5GB | 10GB |## ğŸ› ï¸ Tecnologias Utilizadas

| **CPU** | 4 cores | 8+ cores |

| **GPU** | NÃ£o necessÃ¡ria | Acelera LLM |- **Python 3.8+**

| **SO** | Windows 10 | Windows 11 |- **Tkinter**: Interface grÃ¡fica

| **Python** | 3.8 | 3.10+ |- **LangChain**: Framework para IA e RAG

- **ChromaDB**: Banco de dados vetorial

**Nota**: Modelos LLM maiores (70B+) requerem 32GB+ RAM.- **Ollama**: Servidor de LLM local

- **PyMuPDF**: Processamento de PDFs

---

## ğŸ“ LicenÃ§a

## ğŸ›¡ï¸ Privacidade e SeguranÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

âœ… **100% Local**: Nenhum dado enviado para nuvem  

âœ… **Offline**: Funciona sem internet apÃ³s setup  ## ğŸ¤ ContribuiÃ§Ãµes

âœ… **Privacidade Total**: Seus PDFs ficam no seu PC  

âœ… **Sem Telemetria**: Sem rastreamento ou analytics  ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues ou pull requests.

âœ… **Open Source**: CÃ³digo auditÃ¡vel  

## ğŸ“§ Contato

---

- GitHub: [@victormedrado99](https://github.com/victormedrado99)

## ğŸ“š DocumentaÃ§Ã£o Adicional- RepositÃ³rio: [local_chatbot_RAG](https://github.com/victormedrado99/local_chatbot_RAG)



- ğŸ“˜ **VISUAL_RETRO_90s.md** - Guia completo do visual retro---

- ğŸ“— **RERANKING.md** - TÃ©cnica de re-ranking explicada

- ğŸ“™ **STREAMING.md** - Como funciona streaming de respostas**Desenvolvido com â¤ï¸ usando Python, LangChain e Ollama**

- ğŸ“• **FONTES_MELHORADAS.md** - Sistema de citaÃ§Ãµes inteligentes

---

## ğŸ® Features Implementadas

### âœ… Core RAG
- [x] Embeddings com nomic-embed-text
- [x] Vector store com ChromaDB persistente
- [x] LLM local com deepseek-r1:8b
- [x] Processamento de PDFs com PyMuPDF

### âœ… Advanced Features
- [x] Cross-encoder re-ranking (ms-marco)
- [x] Streaming de respostas palavra-por-palavra
- [x] CitaÃ§Ãµes com snippets de 200 chars
- [x] Truncamento inteligente em limites de palavra

### âœ… Interface
- [x] GUI Tkinter com tema retro
- [x] Terminal integrado com cores diferenciadas
- [x] ASCII art borders e separadores
- [x] BotÃµes estilo DOS com sÃ­mbolos
- [x] Mensagens terminal com prefixos >>>
- [x] Cursor largo tipo DOS
- [x] Threading para operaÃ§Ãµes assÃ­ncronas

### âœ… UX Improvements
- [x] Cores diferenciadas (bot verde, user ciano, fontes amarelo)
- [x] Feedback visual de processamento
- [x] Mensagens de erro amigÃ¡veis
- [x] ConfirmaÃ§Ãµes de operaÃ§Ãµes
- [x] Status de carregamento de modelos

---

## ğŸš€ Roadmap Futuro

### PossÃ­veis Melhorias
- [ ] Efeito scanlines CRT
- [ ] Glow/bloom em texto verde
- [ ] Sons retro (beeps, clicks)
- [ ] Boot sequence animada
- [ ] Suporte para outros formatos (TXT, DOCX)
- [ ] HistÃ³rico de conversas
- [ ] Export de respostas
- [ ] ConfiguraÃ§Ãµes via GUI
- [ ] Temas customizÃ¡veis

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a **MIT**.

---

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! 

**Como contribuir:**
1. Fork o projeto
2. Crie uma branch: `git checkout -b minha-feature`
3. Commit suas mudanÃ§as: `git commit -m 'Adiciona feature X'`
4. Push para a branch: `git push origin minha-feature`
5. Abra um Pull Request

---

## ğŸ“§ Contato

- **GitHub**: [@victormedrado99](https://github.com/victormedrado99)
- **RepositÃ³rio**: [local_chatbot_RAG](https://github.com/victormedrado99/local_chatbot_RAG)

---

## ğŸ‰ Agradecimentos

- **LangChain** - Framework RAG incrÃ­vel
- **Ollama** - Servidor LLM local simplificado
- **ChromaDB** - Vector store eficiente
- **Sentence-Transformers** - Modelos de re-ranking
- **Comunidade Open Source** - Por tornar tudo possÃ­vel

---

**Desenvolvido com ğŸ’š usando Python, LangChain e Ollama**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  CHATBOT RAG v1.0 - TERMINAL RETRO EDITION    â•‘
â•‘  "Bringing back the 90s, one terminal at a    â•‘
â•‘   time..." - Powered by AI ğŸ•¹ï¸                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```
